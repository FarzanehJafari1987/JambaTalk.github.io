<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description" content="JambaTalk: JambaTalk: Speech-driven 3D Talking Head Generation based on Hybrid Transformer-Mamba Model">
  <meta name="keywords" content="Computing methodologies â†’ Animation; Artificial intelligence; Image manipulation.">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>JambaTalk</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/bulma/0.9.4/css/bulma.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">

  <style>
    body {
      font-family: 'Google Sans', sans-serif;
      background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
      min-height: 100vh;
    }

    .hero {
      background: rgba(255, 255, 255, 0.95);
      backdrop-filter: blur(10px);
      border-radius: 20px;
      margin: 2rem;
      box-shadow: 0 20px 40px rgba(0, 0, 0, 0.1);
      overflow: hidden;
    }

    .hero-body {
      padding: 3rem 1.5rem;
    }

    .publication-title {
      background: linear-gradient(135deg, #667eea, #764ba2);
      -webkit-background-clip: text;
      -webkit-text-fill-color: transparent;
      font-weight: 700;
      line-height: 1.2;
      margin-bottom: 1.5rem;
    }

    .author-block {
      margin: 0 0.3rem;
    }

    .author-block a {
      color: #4a5568;
      text-decoration: none;
      transition: all 0.3s ease;
    }

    .author-block a:hover {
      color: #667eea;
      transform: translateY(-1px);
    }

    .publication-links {
      margin-top: 2rem;
    }

    .button {
      margin: 0.5rem;
      transition: all 0.3s ease;
      background: rgba(102, 126, 234, 0.1);
      border: 2px solid #667eea;
      color: #667eea;
    }

    .button:hover {
      background: #667eea;
      color: white;
      transform: translateY(-2px);
      box-shadow: 0 10px 25px rgba(102, 126, 234, 0.3);
    }

    .teaser {
      margin: 2rem;
      background: rgba(255, 255, 255, 0.95);
      border-radius: 20px;
      overflow: hidden;
      box-shadow: 0 20px 40px rgba(0, 0, 0, 0.1);
    }

    .teaser video {
      width: 100%;
      height: auto;
      border-radius: 15px;
      box-shadow: 0 10px 30px rgba(0, 0, 0, 0.2);
    }

    .subtitle {
      margin-top: 1.5rem !important;
      font-size: 1.25rem;
      color: #4a5568;
      line-height: 1.6;
    }

    .section {
      background: rgba(255, 255, 255, 0.95);
      margin: 2rem;
      border-radius: 20px;
      backdrop-filter: blur(10px);
      box-shadow: 0 20px 40px rgba(0, 0, 0, 0.1);
    }

    .title.is-3 {
      color: #2d3748;
      margin-bottom: 2rem;
      position: relative;
    }

    .title.is-3::after {
      content: '';
      position: absolute;
      bottom: -10px;
      left: 50%;
      transform: translateX(-50%);
      width: 60px;
      height: 4px;
      background: linear-gradient(135deg, #667eea, #764ba2);
      border-radius: 2px;
    }

    .content p {
      font-size: 1.1rem;
      line-height: 1.8;
      color: #4a5568;
    }

    .method-image {
      width: 100%;
      border-radius: 15px;
      box-shadow: 0 15px 35px rgba(0, 0, 0, 0.1);
      margin: 2rem 0;
      transition: transform 0.3s ease;
    }

    .method-image:hover {
      transform: scale(1.02);
    }

    .svg-inline {
      display: inline-block;
      vertical-align: middle;
      background: linear-gradient(135deg, #667eea, #764ba2);
      color: white;
      padding: 2px 8px;
      border-radius: 4px;
      font-style: italic;
      font-weight: bold;
    }

    pre {
      background: #2d3748 !important;
      border-radius: 10px;
      padding: 1.5rem;
      overflow-x: auto;
    }

    pre code {
      color: #e2e8f0;
      font-size: 0.9rem;
      line-height: 1.6;
    }

    .footer {
      background: rgba(255, 255, 255, 0.9);
      margin: 2rem;
      border-radius: 20px;
      backdrop-filter: blur(10px);
    }

    .icon-link {
      margin: 0 1rem;
      font-size: 1.5rem;
      color: #667eea;
      transition: all 0.3s ease;
    }

    .icon-link:hover {
      color: #764ba2;
      transform: translateY(-2px);
    }

    .navbar {
      background: rgba(255, 255, 255, 0.95);
      backdrop-filter: blur(10px);
      box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
    }

    @keyframes fadeInUp {
      from {
        opacity: 0;
        transform: translateY(30px);
      }
      to {
        opacity: 1;
        transform: translateY(0);
      }
    }

    .hero-body > * {
      animation: fadeInUp 0.8s ease;
    }

    .section > * {
      animation: fadeInUp 0.8s ease;
    }

    @media (max-width: 768px) {
      .hero, .teaser, .section, .footer {
        margin: 1rem;
      }
      
      .publication-title {
        font-size: 1.8rem !important;
      }
      
      .button {
        margin: 0.25rem;
        font-size: 0.9rem;
      }
    }

    /* Floating animation for the method diagram */
    @keyframes float {
      0% { transform: translateY(0px); }
      50% { transform: translateY(-10px); }
      100% { transform: translateY(0px); }
    }

    .method-image {
      animation: float 6s ease-in-out infinite;
    }

    /* Gradient text animation */
    @keyframes gradientShift {
      0% { background-position: 0% 50%; }
      50% { background-position: 100% 50%; }
      100% { background-position: 0% 50%; }
    }

    .publication-title {
      background: linear-gradient(-45deg, #667eea, #764ba2, #f093fb, #f5576c);
      background-size: 400% 400%;
      animation: gradientShift 4s ease infinite;
      -webkit-background-clip: text;
      -webkit-text-fill-color: transparent;
    }
  </style>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
<!--           <h1 class="title is-1 publication-title">ACM MM 2023</h1> -->
          <h1 class="title is-1 publication-title">JambaTalk: Speech-driven 3D Talking Head Generation based on Hybrid Transformer-Mamba Model</h1>
          
          <div class="is-size-5 publication-authors">
            <span class="author-block">
<!--               <a href="https://ziqiaopeng.github.io/">Ziqiao Peng</a><sup>1</sup>, -->
            </span>
            <span class="author-block">
              <strong>Farzaneh Jafari </strong><sup>1</sup>,
            </span>
            <span class="author-block">
              <strong>Stefano Berretti </strong><sup>2</sup>,
            </span>
            <span class="author-block">
              <strong>Anup Basu </strong><sup>1</sup>,
            </span>
            <br>
<!--             <span class="author-block">
              <a href="https://www.sem.tsinghua.edu.cn/info/1189/32080.htm">Hongyan Liu</a><sup>6</sup>,
            </span>
            <span class="author-block">
              <a href="http://info.ruc.edu.cn/jsky/rtjs/d696a551fefc4b0ab6f90e02b01f3529.htm">Jun He</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://fanzhaoxin666.github.io/">Zhaoxin Fan</a><sup>1,3</sup>
            </span> -->
          </div>

          <div class="is-size-6 publication-authors" style="margin-top: 1rem;">
            <span class="author-block"><sup>1</sup>University of Alberta, Multimedia Research Center (MRC), Canada,</span>
            <span class="author-block"><sup>2</sup>University of Florence, Media Integration and Communication Center (MICC), Italy</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <span class="link-block">
                <a href="https://arxiv.org/abs/2408.01627" class="external-link button is-normal is-rounded">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <span class="link-block">
                <a href="#teaser" class="external-link button is-normal is-rounded">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://github.com/FarzanehJafari1987/JambaTalk" class="external-link button is-normal is-rounded">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" autoplay loop controls playsinline style="width: 100%; height: auto; border-radius: 15px;">
        <source src="https://via.placeholder.com/800x450/667eea/ffffff?text=JambaTalk+Demo+Video" type="video/mp4">
        <!-- Fallback placeholder -->
        <div style="width: 100%; height: 450px; background: linear-gradient(135deg, #667eea, #764ba2); display: flex; align-items: center; justify-content: center; color: white; font-size: 2rem; border-radius: 15px;">
          JambaTalk Demo Video
        </div>
      </video>
      <h2 class="subtitle has-text-centered">
        <strong>JambaTalk</strong> utilizes a cross-modal network system to generate coherent and visually comprehensible 3D talking faces by reducing the domain gap between different modalities.
      </h2>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            In recent years, the talking head generation has become a focal point for researchers. Considerable effort is being 
            made to refine lip-sync motion, capture expressive facial expressions, generate natural head poses, and achieve high
            video quality. However, no single model has yet achieved equivalence across all these metrics. This paper aims to 
            animate a 3D face using Jamba, a hybrid Transformer-Mamba model. Mamba, a pioneering Structured State Space Model (SSM) 
            architecture, was developed to overcome the limitations of conventional Transformer architectures, particularly in handling
            long sequences. This challenge has constrained traditional models. Jamba merges the advantages of both the Transformer and 
            Mamba approaches, providing a holistic solution. Based on the foundational Jamba block, we present JambaTalk to enhance motion 
            variety and speed through multimodal integration. Extensive experiments reveal that our method achieves performance comparable 
            or superior to state-of-the-art models.
            
<!--             Speech-driven 3D face animation technique, extending its applications to various multimedia fields.
            Previous research has generated promising realistic lip movements and facial expressions from audio signals.
            However, traditional regression models solely driven by data face several essential problems, such as difficulties 
            in accessing precise labels and domain gaps between different modalities, leading to unsatisfactory results lacking precision and coherence.
          </p>
          <p>
            To enhance the visual accuracy of generated lip movement while reducing the dependence on labeled data, we propose a novel framework <strong>SelfTalk</strong>, by involving self-supervision in a cross-modals network system to learn 3D talking faces.
            The framework constructs a network system consisting of three modules: facial animator, speech recognizer, and lip-reading interpreter. 
            The core of JambaTalk is a commutative training diagram that facilitates compatible features exchange among audio, text, and lip shape, enabling our models to learn the intricate connection between these factors. The proposed framework leverages the knowledge learned from the lip-reading interpreter to generate more plausible lip shapes.
          </p>
          <p>
            Extensive experiments and user studies demonstrate that our proposed approach achieves state-of-the-art performance both qualitatively and quantitatively. -->
          </p>
        </div>
      </div>
    </div>
    
    <div class="columns is-centered has-text-centered" style="margin-top: 3rem;">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Proposed Method</h2>
        <div class="content has-text-justified">
          <div style="background: linear-gradient(135deg, #f5f7fa, #c3cfe2); padding: 2rem; border-radius: 15px; margin: 2rem 0;">
            <div style="background: white; padding: 2rem; border-radius: 10px; text-align: center;">
              <div style="font-size: 3rem; margin-bottom: 1rem;">ðŸŽ­</div>
<!--               <h4 style="color: #667eea; margin-bottom: 1rem;">Commutative Training Diagram</h4> -->
              <div style="display: flex; justify-content: space-around; flex-wrap: wrap; margin: 2rem 0;">
                <div style="margin: 1rem; text-align: center;">
<!--                   <div style="width: 100px; height: 100px; border-radius: 50%; background: linear-gradient(135deg, #667eea, #764ba2); display: flex; align-items: center; justify-content: center; margin: 0 auto 0.5rem; color: white; font-weight: bold;">Audio</div> -->
                  <span class="svg-inline">A</span>
                </div>
                <div style="margin: 1rem; text-align: center;">
<!--                   <div style="width: 100px; height: 100px; border-radius: 50%; background: linear-gradient(135deg, #f093fb, #f5576c); display: flex; align-items: center; justify-content: center; margin: 0 auto 0.5rem; color: white; font-weight: bold;">Face</div> -->
                  <span class="svg-inline">Y</span>
                </div>
                <div style="margin: 1rem; text-align: center;">
<!--                   <div style="width: 100px; height: 100px; border-radius: 50%; background: linear-gradient(135deg, #4facfe, #00f2fe); display: flex; align-items: center; justify-content: center; margin: 0 auto 0.5rem; color: white; font-weight: bold;">Text</div> -->
                  <span class="svg-inline">S</span>
                </div>
              </div>
            </div>
          </div>
          
          <p style="margin-top: 2rem;">
<!--             Overview of the proposed SelfTalk. We constructed a commutative training diagram consisting of three modules: facial animator, 
            speech recognizer, and lip-reading interpreter. Specifically, given an input audio signal <span class="svg-inline">A</span>, the facial animator 
            module extracts the corresponding facial animation <span class="svg-inline">Y</span>, which constitutes the core component of our framework.
            The speech recognizer, on the other hand, is capable of producing the corresponding text <span class="svg-inline">S</span> and utilizing it as a 
            ground truth label for supervision. Lastly, the lip-reading interpreter interprets lip movements, produces a text distribution 
            and establishes a constraint using the label from <span class="svg-inline">E</span>. -->
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- <section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@inproceedings{peng2023selftalk,
  title={SelfTalk: A Self-Supervised Commutative Training Diagram to Comprehend 3D Talking Faces}, 
  author={Ziqiao Peng and Yihao Luo and Yue Shi and Hao Xu and Xiangyu Zhu and Hongyan Liu and Jun He and Zhaoxin Fan},
  booktitle={Proceedings of the 31st ACM International Conference on Multimedia},
  pages = {5292â€“5301},
  doi = {10.1145/3581783.3611734},
  year={2023}
}</code></pre>
  </div>
</section> -->

<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link" href="https://arxiv.org/pdf/2408.01627" style="margin: 0 1rem;">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/FarzanehJafari1987/JambaTalk" style="margin: 0 1rem;">
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p style="text-align:center; margin-top: 2rem;">
            Â© 2025 JambaTalk Research Project. All rights reserved.</a>.
          </p>
          <p style="text-align:center;">
<!--             Website source code based on the <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a> project page. -->
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

<script>
// Smooth scrolling for anchor links
document.querySelectorAll('a[href^="#"]').forEach(anchor => {
    anchor.addEventListener('click', function (e) {
        e.preventDefault();
        const target = document.querySelector(this.getAttribute('href'));
        if (target) {
            target.scrollIntoView({
                behavior: 'smooth',
                block: 'start'
            });
        }
    });
});

// Add scroll animations
const observerOptions = {
    threshold: 0.1,
    rootMargin: '0px 0px -50px 0px'
};

const observer = new IntersectionObserver((entries) => {
    entries.forEach(entry => {
        if (entry.isIntersecting) {
            entry.target.style.opacity = '1';
            entry.target.style.transform = 'translateY(0)';
        }
    });
}, observerOptions);

// Observe all sections for animation
document.querySelectorAll('.section, .hero, .teaser').forEach(section => {
    section.style.opacity = '0';
    section.style.transform = 'translateY(30px)';
    section.style.transition = 'all 0.8s ease';
    observer.observe(section);
});

// Auto-play video when in view
const videoObserver = new IntersectionObserver((entries) => {
    entries.forEach(entry => {
        const video = entry.target;
        if (entry.isIntersecting) {
            video.play();
        } else {
            video.pause();
        }
    });
}, { threshold: 0.5 });

const video = document.getElementById('teaser');
if (video) {
    videoObserver.observe(video);
}
</script>

</body>
</html>
